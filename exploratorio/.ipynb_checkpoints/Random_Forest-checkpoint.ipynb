{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de resgistros nulos: 0\n",
      "\n",
      "\n",
      "Valores únicos en CADASTRALQUALITYID: ['2' '8' '5' '6' '4' '7' '3' 12 '1' '9' 11 10]\n",
      "\n",
      "\n",
      "CLASES: ['RESIDENTIAL' 'INDUSTRIAL' 'PUBLIC' 'OFFICE' 'OTHER' 'RETAIL'\n",
      " 'AGRICULTURE']\n",
      "CLASE en numérico: [5 1 4 2 3 6 0]\n",
      "\n",
      "\n",
      "Nº de observaciones por CLASE\n",
      "5    90173\n",
      "1     4486\n",
      "4     2976\n",
      "6     2092\n",
      "2     1828\n",
      "3     1332\n",
      "0      323\n",
      "Name: CLASE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Modelar_UH2020.txt\", sep = \"|\")\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "print(f\"Nº de resgistros nulos: {df.isnull().sum().max()}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "df[\"CADASTRALQUALITYID\"].replace(\"A\", 10, inplace = True)\n",
    "df[\"CADASTRALQUALITYID\"].replace(\"B\", 11, inplace = True)\n",
    "df[\"CADASTRALQUALITYID\"].replace(\"C\", 12, inplace = True)\n",
    "print(f\"Valores únicos en CADASTRALQUALITYID: {df.CADASTRALQUALITYID.unique()}\")\n",
    "print(\"\\n\")\n",
    "print(f\"CLASES: {df.CLASE.unique()}\")\n",
    "df.CLASE = pd.Categorical(df.CLASE)\n",
    "df.CLASE = df.CLASE.cat.codes\n",
    "print(f\"CLASE en numérico: {df.CLASE.unique()}\")\n",
    "print(\"\\n\")\n",
    "#Chequeo de \"no balanceo\"\n",
    "print(\"Nº de observaciones por CLASE\")\n",
    "print(df[\"CLASE\"].value_counts())\n",
    "\n",
    "df.drop(df[[\"ID\"]], axis = \"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'Q_R_4_0_0', 'Q_R_4_0_1', 'Q_R_4_0_2', 'Q_R_4_0_3',\n",
       "       'Q_R_4_0_4', 'Q_R_4_0_5', 'Q_R_4_0_6', 'Q_R_4_0_7', 'Q_R_4_0_8',\n",
       "       'Q_R_4_0_9', 'Q_R_4_1_0', 'Q_G_3_0_0', 'Q_G_3_0_1', 'Q_G_3_0_2',\n",
       "       'Q_G_3_0_3', 'Q_G_3_0_4', 'Q_G_3_0_5', 'Q_G_3_0_6', 'Q_G_3_0_7',\n",
       "       'Q_G_3_0_8', 'Q_G_3_0_9', 'Q_G_3_1_0', 'Q_B_2_0_0', 'Q_B_2_0_1',\n",
       "       'Q_B_2_0_2', 'Q_B_2_0_3', 'Q_B_2_0_4', 'Q_B_2_0_5', 'Q_B_2_0_6',\n",
       "       'Q_B_2_0_7', 'Q_B_2_0_8', 'Q_B_2_0_9', 'Q_B_2_1_0', 'Q_NIR_8_0_0',\n",
       "       'Q_NIR_8_0_1', 'Q_NIR_8_0_2', 'Q_NIR_8_0_3', 'Q_NIR_8_0_4',\n",
       "       'Q_NIR_8_0_5', 'Q_NIR_8_0_6', 'Q_NIR_8_0_7', 'Q_NIR_8_0_8',\n",
       "       'Q_NIR_8_0_9', 'Q_NIR_8_1_0', 'AREA', 'GEOM_R1', 'GEOM_R2', 'GEOM_R3',\n",
       "       'GEOM_R4', 'CONTRUCTIONYEAR', 'MAXBUILDINGFLOOR', 'CADASTRALQUALITYID',\n",
       "       'CLASE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[[\"Q_R_4_0_0\",\"Q_R_4_1_0\",\"Q_G_3_0_0\",\"Q_G_3_1_0\",\"Q_B_2_0_0\",\"Q_B_2_1_0\",\"Q_NIR_8_0_0\",\"Q_NIR_8_1_0\"]], axis = \"columns\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=df[\"GEOM_R3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820\n"
     ]
    }
   ],
   "source": [
    "min_con= df[\"CONTRUCTIONYEAR\"].min()\n",
    "print(min_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CONTRUCTIONYEAR\"] = df[\"CONTRUCTIONYEAR\"] - min_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Nº de observaciones mínimo por clase: 262\n",
      "5    72113\n",
      "1     3617\n",
      "4     2374\n",
      "6     1688\n",
      "2     1464\n",
      "3     1050\n",
      "0      262\n",
      "Name: CLASE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "#train_df, val_df = train_test_split(train_df, test_size=0.3)\n",
    "\n",
    "print(\"\\n\")\n",
    "num_min = min(train_df[\"CLASE\"].value_counts())\n",
    "print(f\"Nº de observaciones mínimo por clase: {num_min}\")\n",
    "print(train_df[\"CLASE\"].value_counts())\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_y = np.array(train_df.pop('CLASE'))\n",
    "#bool_train_labels = train_labels != 0\n",
    "test_y = np.array(test_df.pop('CLASE'))\n",
    "\n",
    "train_X = np.array(train_df)\n",
    "test_X = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "train_X = np.clip(train_X, 0, 1)\n",
    "test_X = np.clip(test_X, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=None, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 1000, criterion = 'entropy', random_state = 42, bootstrap = True, \n",
    "                                    class_weight = \"balanced\", max_features = 'sqrt')\n",
    "classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sin hacer oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   33    10     0     0     2    15     1]\n",
      " [    5   495    39    12     7   294    17]\n",
      " [    0    55    65     4    17   214     9]\n",
      " [    0    11     3    70    24   165     9]\n",
      " [    2    26    13    22   118   409    12]\n",
      " [   12    92    49    90    95 17531   191]\n",
      " [    2    28    14     5    28   264    63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57        61\n",
      "           1       0.69      0.57      0.62       869\n",
      "           2       0.36      0.18      0.24       364\n",
      "           3       0.34      0.25      0.29       282\n",
      "           4       0.41      0.20      0.26       602\n",
      "           5       0.93      0.97      0.95     18060\n",
      "           6       0.21      0.16      0.18       404\n",
      "\n",
      "    accuracy                           0.89     20642\n",
      "   macro avg       0.51      0.41      0.45     20642\n",
      "weighted avg       0.87      0.89      0.88     20642\n",
      "\n",
      "0.8901753706036237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred_y = classifier.predict(test_X)\n",
    "print(confusion_matrix(test_y,pred_y))\n",
    "print(classification_report(test_y,pred_y))\n",
    "print(accuracy_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Búsqueda de Hiperparámetros con RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [10, 31, 52, 73, 94, 115, 136, 157, 178, 200], 'max_features': [3, 5, 'sqrt', 9, 11], 'max_depth': [40, None], 'min_samples_split': [2, 3, 5], 'min_samples_leaf': [2, 4], 'bootstrap': [True], 'class_weight': ['balanced']}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [3, 5, 'sqrt', 9, 11]\n",
    "# Maximum number of levels in tree\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth = [40]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [8, 16, 32]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Balanced data\n",
    "class_weight = [\"balanced\"]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "              'class_weight': class_weight}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 54.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 94.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 118.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_job...\n",
       "                   iid='deprecated', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True],\n",
       "                                        'class_weight': ['balanced'],\n",
       "                                        'max_depth': [40, None],\n",
       "                                        'max_features': [3, 5, 'sqrt', 9, 11],\n",
       "                                        'min_samples_leaf': [2, 4],\n",
       "                                        'min_samples_split': [2, 3, 5],\n",
       "                                        'n_estimators': [10, 31, 52, 73, 94,\n",
       "                                                         115, 136, 157, 178,\n",
       "                                                         200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_h = RandomForestClassifier(random_state=42)\n",
    "# cv = número de subcarpetas en las que se divide el dataset en crossvalidation.\n",
    "# n_iter = número de iteraciones a realizar de diferentes combinaciones\n",
    "rf_random = RandomizedSearchCV(estimator = classifier_h, param_distributions = random_grid, n_iter = 100, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 11,\n",
       " 'max_depth': None,\n",
       " 'class_weight': 'balanced',\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Saco la info de los mejores parámetros para poder utilizarlos en la siguiente celda\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=None, max_features='log2',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_h = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 42, bootstrap = True, \n",
    "                                    class_weight = \"balanced\", max_features = 'log2', min_samples_split = 2,\n",
    "                                    min_samples_leaf = 1, max_depth = None)\n",
    "classifier_h.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   42     8     1     0     0    10     1]\n",
      " [    6   566    26     6     5   321     6]\n",
      " [    0    64    61     2    10   230     4]\n",
      " [    1    14     0    90     9   154     0]\n",
      " [    1    14    10    19   111   425     0]\n",
      " [    2    31     9     5    27 17869     5]\n",
      " [    2    30    10     1    20   344    70]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.72        62\n",
      "           1       0.78      0.60      0.68       936\n",
      "           2       0.52      0.16      0.25       371\n",
      "           3       0.73      0.34      0.46       268\n",
      "           4       0.61      0.19      0.29       580\n",
      "           5       0.92      1.00      0.96     17948\n",
      "           6       0.81      0.15      0.25       477\n",
      "\n",
      "    accuracy                           0.91     20642\n",
      "   macro avg       0.74      0.45      0.52     20642\n",
      "weighted avg       0.90      0.91      0.89     20642\n",
      "\n",
      "0.911200465071214\n"
     ]
    }
   ],
   "source": [
    "pred_yh = classifier_h.predict(test_X)\n",
    "print(confusion_matrix(test_y,pred_yh))\n",
    "print(classification_report(test_y,pred_yh))\n",
    "print(accuracy_score(test_y, pred_yh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Búsqueda de Hiperparámetros con GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "\n",
    "classifier_h = RandomForestClassifier(random_state=42)\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 50)]\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(30, 80, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [2, 3],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'n_estimators': [200],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = classifier_h, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 66 candidates, totalling 660 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(train_X, train_y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=35, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lo relleno con los hiperparámetros que me salgan\n",
    "classifier_h = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 42, bootstrap = True, \n",
    "                                    class_weight = \"balanced\", max_features = 'sqrt', min_samples_split = 2,\n",
    "                                    min_samples_leaf = 1, max_depth = 35)\n",
    "classifier_h.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   47     6     0     0     2    20     0]\n",
      " [    5   524    20     8    13   293     7]\n",
      " [    0    63    47     3     8   225     7]\n",
      " [    0     7     0    96    17   165     0]\n",
      " [    1    14     9    18   126   456     4]\n",
      " [    5    28     5    13    28 17949     6]\n",
      " [    1    31     5     4    10   285    61]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.63      0.70        75\n",
      "           1       0.78      0.60      0.68       870\n",
      "           2       0.55      0.13      0.21       353\n",
      "           3       0.68      0.34      0.45       285\n",
      "           4       0.62      0.20      0.30       628\n",
      "           5       0.93      1.00      0.96     18034\n",
      "           6       0.72      0.15      0.25       397\n",
      "\n",
      "    accuracy                           0.91     20642\n",
      "   macro avg       0.72      0.44      0.51     20642\n",
      "weighted avg       0.90      0.91      0.89     20642\n",
      "\n",
      "0.9131867067144657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "pred_yh = classifier_h.predict(test_X)\n",
    "print(confusion_matrix(test_y,pred_yh))\n",
    "print(classification_report(test_y,pred_yh))\n",
    "print(accuracy_score(test_y, pred_yh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "train_X1, train_y1 = RandomOverSampler().fit_resample(train_X, train_y)\n",
    "test_X1, test_y1 = RandomOverSampler().fit_resample(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11831  1237   306     0   307  4347     0]\n",
      " [  124 10732   699   123   337  5719   294]\n",
      " [    0  3387  3066    53   746 10338   438]\n",
      " [    0   826   215  8045  1629  7177   136]\n",
      " [   87   741   574   707  4987 10618   314]\n",
      " [    4    51    22    23    77 17833    18]\n",
      " [    0  1442   425   141  1220 11304  3496]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79     18028\n",
      "           1       0.58      0.60      0.59     18028\n",
      "           2       0.58      0.17      0.26     18028\n",
      "           3       0.88      0.45      0.59     18028\n",
      "           4       0.54      0.28      0.36     18028\n",
      "           5       0.26      0.99      0.42     18028\n",
      "           6       0.74      0.19      0.31     18028\n",
      "\n",
      "    accuracy                           0.48    126196\n",
      "   macro avg       0.65      0.48      0.47    126196\n",
      "weighted avg       0.65      0.48      0.47    126196\n",
      "\n",
      "0.47537164410916355\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(train_X1, train_y1)\n",
    "\n",
    "pred_y1 = classifier.predict(test_X1)\n",
    "print(confusion_matrix(test_y1,pred_y1))\n",
    "print(classification_report(test_y1,pred_y1))\n",
    "print(accuracy_score(test_y1, pred_y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "train_X2, train_y2 = ADASYN().fit_resample(train_X, train_y)\n",
    "test_X2, test_y2 = ADASYN().fit_resample(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8cc9e31cbc2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpred_y2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_y2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_y2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 877\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    878\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier.fit(train_X2, train_y2)\n",
    "\n",
    "pred_y2 = classifier.predict(test_X2)\n",
    "print(confusion_matrix(test_y2,pred_y2))\n",
    "print(classification_report(test_y2,pred_y2))\n",
    "print(accuracy_score(test_y2, pred_y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "train_X3, train_y3 = SMOTE().fit_resample(train_X, train_y)\n",
    "test_X3, test_y3 = SMOTE().fit_resample(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(train_X3, train_y3)\n",
    "\n",
    "pred_y3 = classifier.predict(test_X3)\n",
    "print(confusion_matrix(test_y3,pred_y3))\n",
    "print(classification_report(test_y3,pred_y3))\n",
    "print(accuracy_score(test_y3, pred_y3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondafbbf9993afd04a5b9cc7caeb335224fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
